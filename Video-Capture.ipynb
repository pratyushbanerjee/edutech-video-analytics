{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from collections import OrderedDict \n",
    "from imutils import face_utils\n",
    "import imutils\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEEPGAZE] head_pose_estimation.py: the dlib library is installed.\n"
     ]
    }
   ],
   "source": [
    "import deepgaze\n",
    "from deepgaze.deepgaze.head_pose_estimation import CnnHeadPoseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\data\\COE-ANALYTICS\\FINAL\\deepgaze\\deepgaze\\head_pose_estimation.py:234: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\data\\COE-ANALYTICS\\FINAL\\deepgaze\\deepgaze\\head_pose_estimation.py:239: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\data\\COE-ANALYTICS\\FINAL\\deepgaze\\deepgaze\\head_pose_estimation.py:244: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\data\\COE-ANALYTICS\\FINAL\\deepgaze\\deepgaze\\head_pose_estimation.py:276: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\data\\COE-ANALYTICS\\FINAL\\deepgaze\\deepgaze\\head_pose_estimation.py:439: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samrat.sengupta\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./deepgaze/etc/tensorflow/head_pose/pitch/cnn_cccdd_30k.tf\n",
      "INFO:tensorflow:Restoring parameters from ./deepgaze/etc/tensorflow/head_pose/yaw/cnn_cccdd_30k.tf\n",
      "INFO:tensorflow:Restoring parameters from ./deepgaze/etc/tensorflow/head_pose/roll/cnn_cccdd_30k.tf\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "head_pose_estimator = CnnHeadPoseEstimator(sess)\n",
    "head_pose_estimator.load_pitch_variables('./deepgaze/etc/tensorflow/head_pose/pitch/cnn_cccdd_30k.tf')\n",
    "head_pose_estimator.load_yaw_variables('./deepgaze/etc/tensorflow/head_pose/yaw/cnn_cccdd_30k.tf')\n",
    "head_pose_estimator.load_roll_variables('./deepgaze/etc/tensorflow/head_pose/roll/cnn_cccdd_30k.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left eye points: (36, 37, 38, 39, 40, 41)\n",
    "# Right eye points: (42, 43, 44, 45, 46, 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(p1 ,p2):\n",
    "    return int((p1.x + p2.x)/2), int((p1.y + p2.y)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def yaw2rotmat(yaw):\n",
    "#     x = 0.0\n",
    "#     y = 0.0\n",
    "#     z = yaw\n",
    "#     ch = np.cos(z)\n",
    "#     sh = np.sin(z)\n",
    "#     ca = np.cos(y)\n",
    "#     sa = np.sin(y)\n",
    "#     cb = np.cos(x)\n",
    "#     sb = np.sin(x)\n",
    "#     rot = np.zeros((3,3), 'float32')\n",
    "#     rot[0][0] = ch * ca\n",
    "#     rot[0][1] = sh*sb - ch*sa*cb\n",
    "#     rot[0][2] = ch*sa*sb + sh*cb\n",
    "#     rot[1][0] = sa\n",
    "#     rot[1][1] = ca * cb\n",
    "#     rot[1][2] = -ca * sb\n",
    "#     rot[2][0] = -sh * ca\n",
    "#     rot[2][1] = sh*sa*cb + ch*sb\n",
    "#     rot[2][2] = -sh*sa*sb + ch*cb\n",
    "#     return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data points  pitch :  [[[0.03217963]]]  roll  [[[-0.00017241]]]  yaw  [[[-0.19646515]]]\n",
      "data points  pitch :  [[[0.13273744]]]  roll  [[[0.11418705]]]  yaw  [[[-0.42283544]]]\n",
      "data points  pitch :  [[[0.14273395]]]  roll  [[[0.10289573]]]  yaw  [[[-0.43410265]]]\n",
      "data points  pitch :  [[[0.12930559]]]  roll  [[[0.11245632]]]  yaw  [[[-0.40388376]]]\n",
      "data points  pitch :  [[[-0.08411925]]]  roll  [[[-0.05071685]]]  yaw  [[[0.39250508]]]\n",
      "data points  pitch :  [[[0.04117327]]]  roll  [[[-0.01877896]]]  yaw  [[[0.38506985]]]\n",
      "data points  pitch :  [[[0.0626554]]]  roll  [[[-0.00962131]]]  yaw  [[[0.398794]]]\n",
      "data points  pitch :  [[[0.05368046]]]  roll  [[[-0.01459606]]]  yaw  [[[0.38941616]]]\n",
      "data points  pitch :  [[[0.04697675]]]  roll  [[[-0.02001482]]]  yaw  [[[0.36717257]]]\n",
      "data points  pitch :  [[[0.05324829]]]  roll  [[[0.11855651]]]  yaw  [[[-0.14684114]]]\n",
      "data points  pitch :  [[[0.08256634]]]  roll  [[[0.10951939]]]  yaw  [[[-0.250717]]]\n",
      "data points  pitch :  [[[0.04861128]]]  roll  [[[0.10767221]]]  yaw  [[[-0.17039399]]]\n",
      "data points  pitch :  [[[0.0545758]]]  roll  [[[0.12251551]]]  yaw  [[[-0.35132268]]]\n",
      "data points  pitch :  [[[0.08735214]]]  roll  [[[0.10974891]]]  yaw  [[[-0.29434094]]]\n",
      "data points  pitch :  [[[0.11338138]]]  roll  [[[0.0717171]]]  yaw  [[[-0.28622282]]]\n",
      "data points  pitch :  [[[-0.06456096]]]  roll  [[[-0.00117953]]]  yaw  [[[-0.5667199]]]\n",
      "data points  pitch :  [[[-0.08192094]]]  roll  [[[0.01165108]]]  yaw  [[[-0.62890154]]]\n",
      "data points  pitch :  [[[-0.08838551]]]  roll  [[[0.01271484]]]  yaw  [[[-0.71500343]]]\n",
      "data points  pitch :  [[[0.06635725]]]  roll  [[[0.09630089]]]  yaw  [[[-0.26603365]]]\n",
      "data points  pitch :  [[[0.07543159]]]  roll  [[[0.11671493]]]  yaw  [[[-0.2621829]]]\n",
      "data points  pitch :  [[[0.05724932]]]  roll  [[[0.13331527]]]  yaw  [[[-0.24581216]]]\n",
      "data points  pitch :  [[[-0.11545974]]]  roll  [[[-0.01262962]]]  yaw  [[[-0.25360933]]]\n",
      "data points  pitch :  [[[-0.00143895]]]  roll  [[[-0.03317191]]]  yaw  [[[0.13698238]]]\n",
      "data points  pitch :  [[[-0.00652788]]]  roll  [[[0.04820379]]]  yaw  [[[-0.71707284]]]\n",
      "data points  pitch :  [[[0.0291778]]]  roll  [[[0.06074378]]]  yaw  [[[-0.6939205]]]\n",
      "data points  pitch :  [[[0.0177304]]]  roll  [[[0.05823768]]]  yaw  [[[-0.47960526]]]\n",
      "data points  pitch :  [[[0.06283288]]]  roll  [[[0.08181173]]]  yaw  [[[-0.01466891]]]\n",
      "data points  pitch :  [[[0.03060992]]]  roll  [[[-0.06378554]]]  yaw  [[[-0.72249407]]]\n",
      "data points  pitch :  [[[0.01355051]]]  roll  [[[-0.06471382]]]  yaw  [[[-0.7596978]]]\n",
      "data points  pitch :  [[[0.03523447]]]  roll  [[[0.08841287]]]  yaw  [[[-0.00432658]]]\n",
      "data points  pitch :  [[[-0.01790574]]]  roll  [[[0.06678136]]]  yaw  [[[-0.11939281]]]\n",
      "data points  pitch :  [[[0.01931173]]]  roll  [[[0.05282472]]]  yaw  [[[-0.14741711]]]\n",
      "data points  pitch :  [[[-0.00681039]]]  roll  [[[0.08967318]]]  yaw  [[[-0.18468636]]]\n",
      "data points  pitch :  [[[-0.04015905]]]  roll  [[[0.00099545]]]  yaw  [[[-0.28493145]]]\n",
      "data points  pitch :  [[[0.04555118]]]  roll  [[[0.05182365]]]  yaw  [[[-0.39905262]]]\n",
      "data points  pitch :  [[[0.01428476]]]  roll  [[[0.05332683]]]  yaw  [[[-0.07903182]]]\n",
      "data points  pitch :  [[[0.01297323]]]  roll  [[[-0.03696679]]]  yaw  [[[-0.6906238]]]\n",
      "data points  pitch :  [[[-0.0707342]]]  roll  [[[0.07262204]]]  yaw  [[[-0.22311021]]]\n",
      "data points  pitch :  [[[-0.07149377]]]  roll  [[[0.07181382]]]  yaw  [[[-0.19401085]]]\n",
      "data points  pitch :  [[[-0.03023688]]]  roll  [[[0.02645486]]]  yaw  [[[-0.33387986]]]\n",
      "data points  pitch :  [[[-0.05011899]]]  roll  [[[-0.01293314]]]  yaw  [[[-0.45134145]]]\n",
      "data points  pitch :  [[[-0.04886611]]]  roll  [[[-0.04209679]]]  yaw  [[[-0.46962756]]]\n",
      "data points  pitch :  [[[-0.06206113]]]  roll  [[[-0.01658269]]]  yaw  [[[-0.44652462]]]\n",
      "data points  pitch :  [[[0.09653059]]]  roll  [[[0.0020608]]]  yaw  [[[-0.36586976]]]\n",
      "data points  pitch :  [[[0.02465461]]]  roll  [[[-0.06687051]]]  yaw  [[[-0.75084615]]]\n",
      "data points  pitch :  [[[-0.03708754]]]  roll  [[[0.05692603]]]  yaw  [[[-0.45336297]]]\n",
      "data points  pitch :  [[[-0.03433472]]]  roll  [[[0.08136684]]]  yaw  [[[-0.38435704]]]\n",
      "data points  pitch :  [[[0.10014012]]]  roll  [[[-0.01711077]]]  yaw  [[[-0.00506781]]]\n",
      "data points  pitch :  [[[0.03308448]]]  roll  [[[-0.00584344]]]  yaw  [[[-0.2296645]]]\n",
      "data points  pitch :  [[[0.04499806]]]  roll  [[[-0.00480089]]]  yaw  [[[-0.70400894]]]\n",
      "data points  pitch :  [[[-0.00531005]]]  roll  [[[0.04228502]]]  yaw  [[[-0.44493175]]]\n",
      "data points  pitch :  [[[-0.03556024]]]  roll  [[[-0.01987291]]]  yaw  [[[-0.606153]]]\n",
      "data points  pitch :  [[[-0.0660368]]]  roll  [[[0.09020365]]]  yaw  [[[-0.39495683]]]\n",
      "data points  pitch :  [[[-0.00313551]]]  roll  [[[0.00377849]]]  yaw  [[[-0.5859804]]]\n",
      "data points  pitch :  [[[0.00879036]]]  roll  [[[-0.02932217]]]  yaw  [[[-0.6060736]]]\n",
      "data points  pitch :  [[[-0.0471952]]]  roll  [[[0.03614544]]]  yaw  [[[-0.32397774]]]\n",
      "data points  pitch :  [[[0.01410738]]]  roll  [[[-0.07596266]]]  yaw  [[[-0.54269254]]]\n",
      "data points  pitch :  [[[0.06216218]]]  roll  [[[-0.00962348]]]  yaw  [[[0.10115826]]]\n",
      "data points  pitch :  [[[0.05675754]]]  roll  [[[-0.00172244]]]  yaw  [[[0.02283948]]]\n",
      "data points  pitch :  [[[0.02193461]]]  roll  [[[-0.01498902]]]  yaw  [[[-0.05613451]]]\n",
      "data points  pitch :  [[[0.0840347]]]  roll  [[[-0.00825521]]]  yaw  [[[-0.02916908]]]\n",
      "data points  pitch :  [[[0.04093463]]]  roll  [[[-0.0015574]]]  yaw  [[[0.03268388]]]\n",
      "data points  pitch :  [[[0.04343593]]]  roll  [[[-0.01922482]]]  yaw  [[[-0.07205404]]]\n",
      "data points  pitch :  [[[0.02275057]]]  roll  [[[-0.04940426]]]  yaw  [[[-0.58987176]]]\n",
      "data points  pitch :  [[[0.03359105]]]  roll  [[[-0.00857024]]]  yaw  [[[0.08637347]]]\n",
      "data points  pitch :  [[[-0.24131587]]]  roll  [[[0.0712973]]]  yaw  [[[0.06683106]]]\n",
      "data points  pitch :  [[[0.03227488]]]  roll  [[[0.07294346]]]  yaw  [[[0.06305727]]]\n",
      "data points  pitch :  [[[0.02055441]]]  roll  [[[0.0537854]]]  yaw  [[[0.1708937]]]\n",
      "data points  pitch :  [[[-0.04684391]]]  roll  [[[0.05970269]]]  yaw  [[[-0.5642183]]]\n",
      "data points  pitch :  [[[-0.04360997]]]  roll  [[[0.06505236]]]  yaw  [[[-0.30775353]]]\n",
      "data points  pitch :  [[[0.02544328]]]  roll  [[[0.09239618]]]  yaw  [[[-0.22199073]]]\n",
      "data points  pitch :  [[[0.04098831]]]  roll  [[[-0.03344894]]]  yaw  [[[-0.65799636]]]\n",
      "data points  pitch :  [[[0.06247654]]]  roll  [[[0.02497522]]]  yaw  [[[0.21510212]]]\n",
      "data points  pitch :  [[[0.02779895]]]  roll  [[[0.00557805]]]  yaw  [[[0.13691443]]]\n",
      "data points  pitch :  [[[-0.06134045]]]  roll  [[[0.00708863]]]  yaw  [[[-0.7276187]]]\n",
      "data points  pitch :  [[[-0.03153116]]]  roll  [[[-0.00156757]]]  yaw  [[[-0.58900875]]]\n",
      "data points  pitch :  [[[0.03599195]]]  roll  [[[-0.0083143]]]  yaw  [[[-0.61854315]]]\n",
      "data points  pitch :  [[[0.01133683]]]  roll  [[[0.06839079]]]  yaw  [[[-0.27851638]]]\n",
      "data points  pitch :  [[[0.01678384]]]  roll  [[[0.11623678]]]  yaw  [[[0.19147773]]]\n",
      "data points  pitch :  [[[-0.0464396]]]  roll  [[[0.05324098]]]  yaw  [[[-0.13746314]]]\n",
      "data points  pitch :  [[[-0.04150597]]]  roll  [[[0.05476984]]]  yaw  [[[-0.21951966]]]\n",
      "data points  pitch :  [[[-0.00350242]]]  roll  [[[0.05945257]]]  yaw  [[[-0.02518562]]]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "# detect faces in the grayscale image\n",
    "    \n",
    "    frame = cv2.resize(frame, (560, 560))   \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #frame_number += 1\n",
    "\n",
    "    # Quit when the input video file ends\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    #rgb_frame = frame[:, :, ::-1]\n",
    "    rects = detector(gray, 1)  \n",
    "    for (i, rect) in enumerate(rects):\n",
    "    # determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "    # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "        # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        #show the face number\n",
    "        cv2.putText(frame, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        #loop over the (x, y)-coordinates for the facial landmarks\n",
    "        #and draw them on the image\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "        landmarks = predictor(gray, rect)\n",
    "        ly_left_point = (landmarks.part(36).x, landmarks.part(36).y)\n",
    "        ly_right_point = (landmarks.part(39).x, landmarks.part(39).y)\n",
    "        \n",
    "        ly_center_top = midpoint(landmarks.part(37), landmarks.part(38))\n",
    "        ly_center_bottom = midpoint(landmarks.part(41), landmarks.part(40))\n",
    "        ly_hor_line = cv2.line(frame, ly_left_point, ly_right_point, (0, 255, 0), 2)\n",
    "        ly_ver_line = cv2.line(frame, ly_center_top, ly_center_top, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        ry_left_point = (landmarks.part(42).x, landmarks.part(42).y)\n",
    "        ry_right_point = (landmarks.part(45).x, landmarks.part(45).y)\n",
    "    \n",
    "        ry_center_top = midpoint(landmarks.part(43), landmarks.part(44))\n",
    "        ry_center_bottom = midpoint(landmarks.part(46), landmarks.part(47))\n",
    "        ry_hor_line = cv2.line(frame, ry_left_point, ry_right_point, (0, 255, 0), 2)\n",
    "        ry_ver_line = cv2.line(frame, ry_center_top, ry_center_bottom, (0, 255, 0), 2)    \n",
    "    \n",
    "\n",
    "#     # Find all the faces and face encodings in the current frame of video\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    face_names = []\n",
    "    #for face_encoding in face_encodings:\n",
    "        # See if the face is a match for the known face(s)\n",
    "#         match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)\n",
    "\n",
    "#         name = None\n",
    "#         if match[0]:\n",
    "#             name = \"Samrat\"\n",
    "    name = 'Samrat'\n",
    "    face_names.append(name)\n",
    "\n",
    "#     # Label the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left-60, top-120), (right+60, bottom+50), (0, 0, 255), 2)\n",
    "        \n",
    "        image = frame[left-60:right+60,top-120:bottom+50]\n",
    "        \n",
    "        image = cv2.resize(image, (480, 480))  \n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        #cv2.rectangle(frame, (left, bottom), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        #cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        pitch = head_pose_estimator.return_pitch(image,radians=True)\n",
    "        yaw = head_pose_estimator.return_yaw(image,radians=True)\n",
    "        roll = head_pose_estimator.return_roll(image,radians=True)\n",
    "        \n",
    "        \n",
    "#         cam_w = frame.shape[1]\n",
    "#         cam_h = frame.shape[0]\n",
    "#         c_x = cam_w / 2\n",
    "#         c_y = cam_h / 2\n",
    "#         f_x = c_x / np.tan(60/2 * np.pi / 180)\n",
    "#         f_y = f_x\n",
    "        \n",
    "#         camera_distortion = np.float32([0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "#         camera_matrix = np.float32([[f_x, 0.0, c_x], [0.0, f_y, c_y], [0.0, 0.0, 1.0]])\n",
    "#         axis = np.float32([[0.0, 0.0, 0.0],[0.0, 0.0, 0.0], [0.0, 0.0, 0.5]])\n",
    "#         tvec = np.array([0.0, 0.0, 1.0], np.float) # translation vector\n",
    "        \n",
    "#         rot_matrix = yaw2rotmat(-yaw[0,0,0])\n",
    "#         rvec, jacobian = cv2.Rodrigues(rot_matrix)\n",
    "#         imgpts, jac = cv2.projectPoints(axis, rvec, tvec, camera_matrix, camera_distortion)\n",
    "        \n",
    "#         p_start = (int(c_x), int(c_y))\n",
    "#         p_stop = (int(imgpts[2][0][0]), int(imgpts[2][0][1]))\n",
    "        \n",
    "#         cv2.line(frame, p_start, p_stop, (0,0,255), 3) #Red\n",
    "#         cv2.circle(frame, p_start, 1, (0,255,0), 3) #Green\n",
    "        \n",
    "        #print(\"Estimated camera matrix: \\n\" + str(camera_matrix) + \"\\n\")\n",
    "    \n",
    "        print('data points ','pitch : ' , pitch ,' roll ' ,roll ,' yaw ',yaw)\n",
    "    \n",
    "    cv2.imshow('pose', frame)    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
